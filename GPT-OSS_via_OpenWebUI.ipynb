{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-OSS mit OpenWebUI in Google Colab\n",
    "\n",
    "Dieses Notizbuch richtet das `gpt-oss:20b`-Modell mit Ollama ein und macht es über eine öffentliche OpenWebUI-Schnittstelle zugänglich.\n",
    "\n",
    "**Anleitung:**\n",
    "1. Stellen Sie sicher, dass Ihre Colab-Laufzeit auf eine GPU-Instanz eingestellt ist (`Laufzeit` > `Laufzeittyp ändern` > `T4 GPU`).\n",
    "2. Führen Sie die Zellen nacheinander aus, indem Sie auf das \"Play\"-Symbol klicken oder `Shift + Enter` drücken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "1. Installation"
   },
   "outputs": [],
   "source": [
    "#@markdown Führen Sie diese Zelle aus, um alle erforderlichen Abhängigkeiten zu installieren.\n",
    "#@markdown > ⏳ **Dies kann einige Minuten dauern.**\n",
    "%%capture\n",
    "print(\"⏳ Installation von Ollama, OpenWebUI und ngrok wird gestartet...\")\n",
    "!pip install open-webui pyngrok nest-asyncio\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "print(\"✅ Installation abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Server starten und auf die Web-UI zugreifen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown Führen Sie diese Zelle aus, um Ollama und OpenWebUI zu starten.\n",
    "#@markdown > ⏳ **Das Herunterladen des Modells kann eine Weile dauern.**\n",
    "import os\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Erlaubt die verschachtelte Verwendung von asyncio.run() in Umgebungen wie Colab\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def run_ollama():\n",
    "    # Ollama im Hintergrund starten\n",
    "    ollama_process = await asyncio.create_subprocess_shell(\n",
    "        'ollama serve',\n",
    "        stdout=asyncio.subprocess.PIPE,\n",
    "        stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "    print(\"⏳ Ollama-Server wird gestartet...\")\n",
    "    # Kurz warten, bis der Server bereit ist\n",
    "    await asyncio.sleep(5)\n",
    "\n",
    "    # Modell herunterladen\n",
    "    print(\"⏳ Lade das gpt-oss:20b Modell herunter. Dies kann einige Zeit dauern...\")\n",
    "    pull_process = await asyncio.create_subprocess_shell(\n",
    "        'ollama pull gpt-oss:20b',\n",
    "        stdout=asyncio.subprocess.PIPE,\n",
    "        stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "    await pull_process.communicate()\n",
    "    print(\"✅ Modell erfolgreich heruntergeladen!\")\n",
    "\n",
    "    # OpenWebUI starten\n",
    "    print(\"⏳ OpenWebUI wird gestartet...\")\n",
    "    os.environ['OLLAMA_BASE_URL'] = 'http://127.0.0.1:11434'\n",
    "    webui_process = await asyncio.create_subprocess_shell(\n",
    "        'open-webui --host 0.0.0.0 --port 8080',\n",
    "        stdout=asyncio.subprocess.PIPE,\n",
    "        stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "    await asyncio.sleep(10) # Zeit geben zum Starten\n",
    "\n",
    "    # Ngrok-Tunnel einrichten und öffentliche URL ausgeben\n",
    "    try:\n",
    "      public_url = ngrok.connect(8080)\n",
    "      print(f\"✅ OpenWebUI ist bereit! Öffnen Sie diesen Link in Ihrem Browser:\\n{public_url}\")\n",
    "    except Exception as e:\n",
    "      print(f\"Fehler beim Starten von ngrok: {e}\")\n",
    "      print(\"Bitte fügen Sie Ihr ngrok-Authtoken in Colab hinzu (siehe Seitenleiste > Geheimnisse) und versuchen Sie es erneut.\")\n",
    "    \n",
    "    # Prozesse am Leben halten\n",
    "    await asyncio.gather(ollama_process.wait(), webui_process.wait())\n",
    "\n",
    "# Führt die asynchrone Funktion aus\n",
    "asyncio.run(run_ollama())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}